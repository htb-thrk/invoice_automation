# modules/docai_processor.py
import os
import re
import json
import tempfile
import logging
from datetime import datetime
from decimal import Decimal, InvalidOperation
from google.cloud import storage, documentai
from google.api_core.client_options import ClientOptions
from vertexai.preview.generative_models import GenerativeModel
import vertexai

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

# ==== ãƒ™ãƒ³ãƒ€ãƒ¼åæ­£è¦åŒ– ====
def normalize_vendor_name(name: str) -> str:
    """
    ãƒ™ãƒ³ãƒ€ãƒ¼åã‚’æ­£è¦åŒ–
    - æ ªå¼ä¼šç¤¾ãªã©ã®æ³•äººæ ¼ã‚’é™¤å»
    - OCRèª¤èªè­˜ï¼ˆå°å½±ï¼‰ã‚’ä¿®æ­£ï¼ˆä¾‹: ã€Œãƒªãƒ³ã‚¯ã‚¯ã€â†’ã€Œãƒªãƒ³ã‚¯ã€ï¼‰
    - å…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
    """
    if not name:
        return name
    
    # æ ªå¼ä¼šç¤¾ã€ï¼ˆæ ªï¼‰ã€ãˆ±ã‚’é™¤å»
    normalized = re.sub(r"æ ªå¼ä¼šç¤¾|ï¼ˆæ ªï¼‰|ãˆ±|\(æ ª\)|æœ‰é™ä¼šç¤¾", "", name)
    
    # OCRèª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿®æ­£ï¼ˆå°å½±ã«ã‚ˆã‚‹é‡è¤‡æ–‡å­—ï¼‰
    ocr_corrections = {
        r"ãƒªãƒ³ã‚¯ã‚¯": "ãƒªãƒ³ã‚¯",
    }
    
    for pattern, replacement in ocr_corrections.items():
        normalized = re.sub(pattern, replacement, normalized)
    
    # å…¨è§’ãƒ»åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
    normalized = re.sub(r"\s+", "", normalized)
    
    logger.debug(f"ãƒ™ãƒ³ãƒ€ãƒ¼åæ­£è¦åŒ–: '{name}' â†’ '{normalized}'")
    return normalized.strip() if normalized else name

# ==== å…±é€šï¼šæ•°å€¤å¤‰æ› ====
def _to_decimal(x):
    """æ•°å€¤æ–‡å­—åˆ—ã‚’Decimalã«å®‰å…¨å¤‰æ›"""
    if x is None:
        return None
    try:
        s = str(x)
        s = re.sub(r"[^\d,\.]", "", s)
        if not s:
            return None
        s = s.replace(",", "")
        return Decimal(s)
    except (InvalidOperation, ValueError):
        return None


# ==== Geminiã‚’ä½¿ç”¨ã—ã¦4é …ç›®ã‚’æŠ½å‡º ====
def extract_with_gemini(text: str, project_id: str) -> dict:
    """
    Gemini 2.0 Flashã‚’ä½¿ç”¨ã—ã¦ vendor / subtotal / total / due_date ã‚’æŠ½å‡º
    """
    fields = {
        "vendor": None,
        "subtotal": None,
        "total": None,
        "due_date": None,
    }

    if not text or len(text) < 40:
        logger.warning("âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™")
        return fields

    try:
        # === GeminiåˆæœŸåŒ– ===
        vertexai.init(project=project_id, location="us-central1")
        model = GenerativeModel("gemini-2.0-flash")

        # === ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ===
        prompt = f"""
ä»¥ä¸‹ã¯è«‹æ±‚æ›¸ã®ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚
æ¬¡ã®4é …ç›®ã‚’æ­£ç¢ºã«æŠ½å‡ºã—ã¦ã€å¿…ãšJSONã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

æŠ½å‡ºãƒ«ãƒ¼ãƒ«:
- vendor: ã€Œæ ªå¼ä¼šç¤¾ã€ã€Œæœ‰é™ä¼šç¤¾ã€ã§å§‹ã¾ã‚‹ç™ºè¡Œä¼šç¤¾å
- subtotal: ã€Œå°è¨ˆã€ã€Œç¨æŠœã€ã€Œå¤–ç¨å¯¾è±¡é‡‘é¡ã€ã®ã„ãšã‚Œã‹ã«å¯¾å¿œã™ã‚‹é‡‘é¡ï¼ˆæ•°å­—ã®ã¿ã€ã‚«ãƒ³ãƒé™¤å»ï¼‰
- total: ã€Œåˆè¨ˆã€ã€Œã”è«‹æ±‚é‡‘é¡ã€ã€Œç·é¡ã€ã€Œç¨è¾¼ã€ã«å¯¾å¿œã™ã‚‹æœ€å¤§ã®é‡‘é¡ï¼ˆæ•°å­—ã®ã¿ã€ã‚«ãƒ³ãƒé™¤å»ï¼‰
- due_date: ã€Œæ”¯æ‰•æœŸé™ã€ã€ŒãŠæ”¯æ‰•æœŸæ—¥ã€ã€Œå…¥é‡‘æœŸæ—¥ã€ã«è©²å½“ã™ã‚‹æ—¥ä»˜ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
- ã€Œç™ºè¡Œæ—¥ã€ã€Œè«‹æ±‚æ—¥ã€ã€Œæ¤œé‡æ—¥ã€ãªã©ã¯æ”¯æ‰•æœŸé™ã¨ã—ã¦æ‰±ã‚ãªã„
- é‡‘é¡ã¯æ—¥æœ¬å††è¡¨è¨˜ã®æœ€å¤§å€¤ã‚’æ¡ç”¨
- JSONä»¥å¤–ã®èª¬æ˜æ–‡ã¯å‡ºåŠ›ç¦æ­¢

ãƒ†ã‚­ã‚¹ãƒˆ:
{text[:2000]}

å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
{{
  "vendor": "...",
  "subtotal": æ•°å­—ã®ã¿,
  "total": æ•°å­—ã®ã¿,
  "due_date": "YYYY-MM-DD"
}}
"""
        response = model.generate_content(prompt)
        raw = (response.text or "").strip()
        logger.info(f"ğŸ¤– Gemini raw output: {raw[:300]}")

        ai_fields = {}
        if raw:
            # JSONéƒ¨åˆ†ã®ã¿æŠ½å‡º
            m = re.search(r"\{.*\}", raw, re.S)
            if m:
                try:
                    ai_fields = json.loads(m.group(0))
                    logger.info(f"âœ… Gemini parsed: {ai_fields}")
                except json.JSONDecodeError as e:
                    logger.warning(f"âš ï¸ JSON parse failed: {e}")
                    ai_fields = {}

        # === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆGeminiãŒå¤±æ•—ã—ãŸå ´åˆï¼‰ ===
        if not ai_fields or not any(ai_fields.values()):
            logger.warning("âš ï¸ Gemini extraction failed, using regex fallback")
            
            company = re.search(r'(?:æ ªå¼|æœ‰é™)ä¼šç¤¾[^\sã€€\n]+', text)
            amount_total = re.search(r"(?:åˆè¨ˆ|ã”è«‹æ±‚é‡‘é¡|ç·é¡)[^\dÂ¥ï¿¥]*[Â¥ï¿¥]?\s*([\d,]+)", text)
            amount_subtotal = re.search(r"(?:å°è¨ˆ|ç¨æŠœé‡‘é¡)[^\dÂ¥ï¿¥]*[Â¥ï¿¥]?\s*([\d,]+)", text)
            due = re.search(r"(?:æ”¯æ‰•æœŸé™|ãŠæ”¯æ‰•æœŸæ—¥|å…¥é‡‘æœŸæ—¥)[^\d]*(\d{4})[å¹´/.\-](\d{1,2})[æœˆ/.\-](\d{1,2})", text)

            if company:
                ai_fields["vendor"] = company.group(0)
            if amount_subtotal:
                val = _to_decimal(amount_subtotal.group(1))
                ai_fields["subtotal"] = float(val) if val else None
            if amount_total:
                val = _to_decimal(amount_total.group(1))
                ai_fields["total"] = float(val) if val else None
            if due:
                y, mo, d = map(int, due.groups())
                ai_fields["due_date"] = datetime(y, mo, d).date().isoformat()

        # === çµæœçµ±åˆ & æ­£è¦åŒ– ===
        vendor_raw = ai_fields.get("vendor")
        fields.update({
            "vendor": normalize_vendor_name(vendor_raw) if vendor_raw else None,
            "subtotal": float(ai_fields.get("subtotal")) if ai_fields.get("subtotal") else None,
            "total": float(ai_fields.get("total")) if ai_fields.get("total") else None,
            "due_date": ai_fields.get("due_date")
        })

        logger.info(f"ğŸ” Final extracted fields: {fields}")

    except Exception as e:
        logger.error(f"âŒ Gemini extraction error: {e}", exc_info=True)

    return fields


# ==== PDFã‚’Document AIã§è§£æ ====
def process_pdf(bucket_name: str, blob_name: str) -> dict:
    """GCSã‹ã‚‰PDFã‚’å–å¾—ã—ã¦Document AIã«é€ä¿¡ã€Geminiã§æŠ½å‡º"""
    logger.info(f"Processing PDF: gs://{bucket_name}/{blob_name}")

    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        storage_client = storage.Client()
        project_id = os.environ["GCP_PROJECT_ID"]
        location = os.environ.get("DOCAI_LOCATION", "us")
        processor_id = os.environ["DOCAI_PROCESSOR_ID"]
        
        docai_client = documentai.DocumentProcessorServiceClient(
            client_options=ClientOptions(api_endpoint=f"{location}-documentai.googleapis.com")
        )

        # GCSã‹ã‚‰PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
            blob.download_to_filename(tmp.name)
            pdf_path = tmp.name

        # Document AIå‘¼ã³å‡ºã—ï¼ˆOCRã®ã¿ï¼‰
        processor_name = docai_client.processor_path(project_id, location, processor_id)
        logger.info(f"ğŸ”§ Using processor: {processor_name}")
        
        with open(pdf_path, "rb") as f:
            raw_document = documentai.RawDocument(content=f.read(), mime_type="application/pdf")
        
        result = docai_client.process_document(request={"name": processor_name, "raw_document": raw_document})
        doc = result.document

        # OCRãƒ†ã‚­ã‚¹ãƒˆå–å¾—
        ocr_text = doc.text or ""
        logger.info(f"ğŸ“„ OCR text length: {len(ocr_text)}")
        logger.info(f"ğŸ“ OCR preview: {ocr_text[:500]}")

        # Geminiã§æŠ½å‡º
        fields = extract_with_gemini(ocr_text, project_id)
        fields["_source"] = {
            "bucket": bucket_name,
            "name": blob_name,
            "processor_id": processor_id,
            "location": location,
            "status": "success"
        }
        
        logger.info(f"âœ… Extracted fields: {fields}")
        return fields

    except Exception as e:
        logger.error(f"âŒ PDF processing error: {e}", exc_info=True)
        return {
            "vendor": None,
            "subtotal": None,
            "total": None,
            "due_date": None,
            "_source": {
                "bucket": bucket_name,
                "name": blob_name,
                "status": "error",
                "error_message": str(e)
            }
        }

